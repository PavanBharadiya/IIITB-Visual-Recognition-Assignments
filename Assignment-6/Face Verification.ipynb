{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for the HaarCascade\n",
    "cascade_path = \"./haarcascade_frontalface_alt2.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "def load_and_align_images(filepaths, margin):\n",
    "    cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    aligned_images = []\n",
    "    labels = []\n",
    "    for filepath in filepaths:\n",
    "        img = imread(filepath)\n",
    "\n",
    "        faces = cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=3)\n",
    "        if len(faces) == 0:\n",
    "            continue\n",
    "            \n",
    "        (x, y, w, h) = faces[0]\n",
    "        cropped = img[y-margin//2:y+h+margin//2, x-margin//2:x+w+margin//2, :]\n",
    "        \n",
    "        if (cropped.shape[0] == 0):\n",
    "            continue\n",
    "        \n",
    "        aligned = resize(cropped, (image_size, image_size), mode='reflect')\n",
    "        aligned_images.append(aligned)\n",
    "        \n",
    "        # need to manunally change it - change it - use a parameter\n",
    "        # for test dataset\n",
    "        # labels.append(filepath.split(\"/\")[-2])\n",
    "        \n",
    "#         for train dataset\n",
    "        labels.append(filepath.split(\"/\")[-1])\n",
    "    \n",
    "    return np.array(aligned_images), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for calculating word embeddings i.e. 128 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating word embeddings i.e. 128 dimensional vector\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def calc_embs(filepaths, margin=10, batch_size=1):\n",
    "    aligned_images, labels = load_and_align_images(filepaths, margin)\n",
    "    aligned_images = prewhiten(aligned_images)\n",
    "    pd = []\n",
    "    for start in range(0, len(aligned_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(aligned_images[start:start+batch_size]))\n",
    "    embs = l2_normalize(np.concatenate(pd))\n",
    "\n",
    "    return embs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading classes names\n",
    "image_dir_basepath_test = \"./test/\"\n",
    "names = os.listdir(image_dir_basepath_test)\n",
    "image_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasu/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# pretrained model path\n",
    "model_path = \"./keras-facenet-20190502T135832Z-001/keras-facenet/model/facenet_keras.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasu/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# getting encoding for test images\n",
    "data = {}\n",
    "\n",
    "for name in names:\n",
    "    image_dirpath = image_dir_basepath_test + name\n",
    "    image_filepaths = [os.path.join(image_dirpath, f) for f in os.listdir(image_dirpath)]\n",
    "    embs, labels = calc_embs(image_filepaths)\n",
    "    \n",
    "    for i in range(len(embs)):\n",
    "        data['{}{}'.format(name, i)] = {'image_filepath' : labels[i], 'emb' : embs[i]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting encodings for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the encodings for training data\n",
    "train_data = {}\n",
    "image_dirpath = \"./training\"\n",
    "image_filepaths = [os.path.join(image_dirpath, f) for f in os.listdir(image_dirpath)]\n",
    "\n",
    "embs, labels = calc_embs(image_filepaths)\n",
    "    \n",
    "for i in range(len(embs)):\n",
    "    train_data['{}{}'.format(name, i)] = {'image_filepath' : labels[i], 'emb' : embs[i]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEAREST NEIGHBOUR CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for every test data we find the closest image to it\n",
    "count = 0\n",
    "for k, v in data.items():\n",
    "    min_dist = 1000\n",
    "    identity = None\n",
    "    for k_train, v_train in train_data.items():\n",
    "        dist = np.linalg.norm(v['emb'] - v_train['emb'])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = v_train['image_filepath']\n",
    "    \n",
    "    if (v['image_filepath'].lower() in identity.lower()):\n",
    "        count = count + 1\n",
    "    else:\n",
    "        pass\n",
    "        # print (v['image_filepath'] + \"   \" + identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192546583850931"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
